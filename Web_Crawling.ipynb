{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['21076849694', '13810664630', '20850829749', '21285691276', '21393999339', '13611653308', '17586234530']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import requests, pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import parse\n",
    "from datetime import datetime\n",
    "\n",
    "# JS로 실행되는 Paging을 Crawling하기 위해서는 selenium Library를 이용하여 직접 화면의 JS를 실행해야한다.\n",
    "# ex) \n",
    "# import time\n",
    "# from selenium import webdriver\n",
    "# from itertools import count\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "# \n",
    "# def crawling_goobne():\n",
    "#     url = 'http://www.goobne.co.kr/store/search_store.jsp'\n",
    "# \n",
    "#     # \\U는 유니코드로 인식되기 때문에 \\\\U와 같이 escape 처리했다.\n",
    "#     wd = webdriver.Chrome('C:\\\\Users\\samsung\\python\\webdriver\\chromedriver.exe')\n",
    "#     wd.get(url)\n",
    "# \n",
    "#     RESULT_DIRECTORY = '__results__/crawling'\n",
    "#     results = []\n",
    "#     for page in count(1):\n",
    "#         script = 'store.getList(%d)' % page  # 굽네치킨에서 사용하는 페이지를 이동시키는 js 코드\n",
    "#          wd.execute_script(script)  # js 실행\n",
    "#          time.sleep(5)              # 크롤링 로직을 수행하기 위해 5초정도 쉬어준다.\n",
    "# \n",
    "#         html = wd.page_source\n",
    "#         bs = BeautifulSoup(html, 'html.parser')\n",
    "#         tag_body = bs.find('tbody', attrs={'id': 'store_list'})\n",
    "#         tags_tr = tag_body.findAll('tr')\n",
    "#         # print(tags_tr)\n",
    "# \n",
    "#         if tags_tr[0].get('class') is None:  # 맨 마지막 페이지인 102에서는 class='on lows'가 없다. => 종료 조건\n",
    "#             break\n",
    "# \n",
    "#         for tag_tr in tags_tr:\n",
    "#             strings = list(tag_tr.strings)\n",
    "#             name = strings[1]\n",
    "#             address = strings[6]\n",
    "#             results.append((name, address))\n",
    "# \n",
    "#     table = pd.DataFrame(results, columns=['name', 'address'])\n",
    "#     table.to_csv('{0}/table_goobne.csv'.format(RESULT_DIRECTORY), encoding='utf-8', mode='w')\n",
    "\n",
    "def get_html(_url, _id):\n",
    "    r = requests.get(_url + _id)\n",
    "    html = BeautifulSoup(r.content, 'html.parser')\n",
    "    \"\"\"\n",
    "    Function select is a copy selector reading from tag. \n",
    "        div { id: section_review, class: detail_cont detail_customer_review }\n",
    "            div { id: _review_filter_container }\n",
    "                ul { id: _review_list, class: lst_review }\n",
    "                    li { class: thumb_nail } or li { class: thumb_nail_open } javascript function execution !\n",
    "    BeatifulSoup API\n",
    "        select(), contents(), extract()\n",
    "    \"\"\"\n",
    "    li_size = len(html.find_all(\"li\", attrs={'class': 'thumb_nail'}))\n",
    "    crawling_arr_set = []\n",
    "    while li_size:\n",
    "        average_star = html.select(\"#_review_list > li:nth-child(%d) > div > div.avg_area > a > span.curr_avg > strong\" % li_size)[0].text\n",
    "        store = html.select(\"#_review_list > li:nth-child(%d) > div > div.avg_area > span > span:nth-child(1)\" % li_size)[0].text\n",
    "        user_name = html.select(\"#_review_list > li:nth-child(%d) > div > div.avg_area > span > span:nth-child(2)\" % li_size)[0].text\n",
    "        write_date = html.select(\"#_review_list > li:nth-child(%d) > div > div.avg_area > span > span:nth-child(3)\" % li_size)[0].text\n",
    "        title_text = html.select(\"#_review_list > li:nth-child(%d) > div > p > strong\" % li_size)[0].text\n",
    "        body_text = html.select(\"#_review_list > li:nth-child(%d) > div > div.atc\" % li_size)[0].text\n",
    "        # print(li_size)\n",
    "        # print(average_star, store, user_name, write_date, title_text, body_text)\n",
    "        crawling_arr_set.append({\n",
    "            \"aver_star\": average_star,\n",
    "            \"user\": user_name,\n",
    "            \"store\": store,\n",
    "            \"date\": write_date,\n",
    "            \"title\": title_text,\n",
    "            \"body\": body_text,\n",
    "            \"product_id\": _id\n",
    "        })\n",
    "        li_size -= 1\n",
    "    return crawling_arr_set\n",
    "\n",
    "'''\n",
    "    Chrome Naver Shopping Raw URL\n",
    "    https://search.shopping.naver.com/detail/detail.nhn?nvMid=21076849694&NaPm=ct%3Dkad8qf08%7Cci%3D0yW0002VbGbs1XUxwvkS%7Ctr%3Dpla%7Chk%3D6066b0a1499f4f77890d54202d9808691c54a75d\"\n",
    "    https://search.shopping.naver.com/detail/detail.nhn?nvMid=13810664630&NaPm=ct%3Dkbkecz08%7Cci%3Da630b02bff9323064460419c72916238067e54e6%7Ctr%3Dslsl%7Csn%3D95694%7Chk%3D6a4ad9a61c99a492bd2beb295b5e65864a233a92\"\n",
    "    parse.unquote() is Decoding the URL parameter.\n",
    "'''\n",
    "\n",
    "NAVER_SHOPPING_BASE_URL = \"https://search.shopping.naver.com/detail/detail.nhn?nvMid=\"\n",
    "KUKU_AC_25W20FPMO = \"21076849694\"\n",
    "DYSON_PURE_COOL_TP_04 = \"13810664630\"\n",
    "ITC_PURIWAY_PW_150 = \"20850829749\"\n",
    "LG_PURICARE_AS300DWFA = \"21285691276\"\n",
    "WINIX_FRIME_APRM833_JWK = \"21393999339\"\n",
    "SAMSUNG_BLUESKY_AX34N3020WWD = \"13611653308\"\n",
    "SKMAGIC_ACL_120Z0 = \"17586234530\"\n",
    "ELECTROMAN_DAP_2215NAWHEM = \"22163383505\"\n",
    "\n",
    "product_arr = [KUKU_AC_25W20FPMO,DYSON_PURE_COOL_TP_04,ITC_PURIWAY_PW_150,LG_PURICARE_AS300DWFA,\n",
    "               WINIX_FRIME_APRM833_JWK, SAMSUNG_BLUESKY_AX34N3020WWD, SKMAGIC_ACL_120Z0]\n",
    "print(product_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Raw :  3월12일 목요일에 주문했는데  월요일에나 도착할줄 알았는데 토요일에 현관앞에 배송완료 했다고 문자가 왔습니다.기쁜마음으로 현관 밖으로 나가보니 물건이 없는겁니다..다시 문자를 확인하고 분명 배송완료 라고 써있어서 문자온 번호로 전화를 하려는 찰나...   배송주소지가 눈에 확 들어오네요.하.. 집을 이사를 하면서 롯데쇼핑에 저장해둔 이전집 주소를  수정하지 않아서  이전집으로 배송이...ㅠ.ㅠ부랴부랴 이전 집으로 가니 다행이  그집 현관앞에 떡하니  있네요 ㅎ이걸 들고 나가는데 마치 남의집 물건 훔쳐가는 기분이..ㅡ.ㅡ여튼 잘 찾아와서  개봉하고 틀어보니 첨엔 하얀불이 들어왔다가  하늘색 불로 바뀌고  금방 파란색 불빛으로 바뀌더군요.아침에 청소하고 환기를 시켜서인지 공기 질이 매우 양호하네요 ㅎㅎ인생에 첨 써보는 공기 청정기라  요긴하게 써봐야겠네요\n",
      "1 :  ['3월12일 목요일에 주문했는데  월요일에나 도착할줄 알았는데 토요일에 현관앞에 배송완료 했다고 문자가 왔습니다.기쁜마음으로 현관 밖으로 나가보니 물건이 없는겁니다..다시 문자를 확인하고 분명 배송완료 라고 써있어서 문자온 번호로 전화를 하려는 찰나...   배송주소지가 눈에 확 들어오네요.하.. 집을 이사를 하면서 롯데쇼핑에 저장해둔 이전집 주소를  수정하지 않아서  이전집으로 배송이...ㅠ.ㅠ부랴부랴 이전 집으로 가니 다행이  그집 현관앞에 떡하니  있네요 ㅎ이걸 들고 나가는데 마치 남의집 물건 훔쳐가는 기분이..ㅡ.ㅡ여튼 잘 찾아와서  개봉하고 틀어보니 첨엔 하얀불이 들어왔다가  하늘색 불로 바뀌고  금방 파란색 불빛으로 바뀌더군요.아침에 청소하고 환기를 시켜서인지 공기 질이 매우 양호하네요 ㅎㅎ인생에 첨 써보는 공기 청정기라  요긴하게 써봐야겠네요']\n",
      "2 :  3월12일 목요일에 주문했는데  월요일에나 도착할줄 알았는데 토요일에 현관앞에 배송완료 했다고 문자가 왔습니다.기쁜마음으로 현관 밖으로 나가보니 물건이 없는겁니다..다시 문자를 확인하고 분명 배송완료 라고 써있어서 문자온 번호로 전화를 하려는 찰나...   배송주소지가 눈에 확 들어오네요.하.. 집을 이사를 하면서 롯데쇼핑에 저장해둔 이전집 주소를  수정하지 않아서  이전집으로 배송이...ㅠ.ㅠ부랴부랴 이전 집으로 가니 다행이  그집 현관앞에 떡하니  있네요 ㅎ이걸 들고 나가는데 마치 남의집 물건 훔쳐가는 기분이..ㅡ.ㅡ여튼 잘 찾아와서  개봉하고 틀어보니 첨엔 하얀불이 들어왔다가  하늘색 불로 바뀌고  금방 파란색 불빛으로 바뀌더군요.아침에 청소하고 환기를 시켜서인지 공기 질이 매우 양호하네요 ㅎㅎ인생에 첨 써보는 공기 청정기라  요긴하게 써봐야겠네요\n",
      "3 :  3월12일목요일에주문했는데월요일에나도착할줄알았는데토요일에현관앞에배송완료했다고문자가왔습니다.기쁜마음으로현관밖으로나가보니물건이없는겁니다..다시문자를확인하고분명배송완료라고써있어서문자온번호로전화를하려는찰나...배송주소지가눈에확들어오네요.하..집을이사를하면서롯데쇼핑에저장해둔이전집주소를수정하지않아서이전집으로배송이...ㅠ.ㅠ부랴부랴이전집으로가니다행이그집현관앞에떡하니있네요ㅎ이걸들고나가는데마치남의집물건훔쳐가는기분이..ㅡ.ㅡ여튼잘찾아와서개봉하고틀어보니첨엔하얀불이들어왔다가하늘색불로바뀌고금방파란색불빛으로바뀌더군요.아침에청소하고환기를시켜서인지공기질이매우양호하네요ㅎㅎ인생에첨써보는공기청정기라요긴하게써봐야겠네요\n",
      "4 :  3월12일목요일에주문했는데월요일에나도착할줄알았는데토요일에현관앞에배송완료했다고문자가왔습니다.기쁜마음으로현관밖으로나가보니물건이없는겁니다..다시문자를확인하고분명배송완료라고써있어서문자온번호로전화를하려는찰나...배송주소지가눈에확들어오네요.하..집을이사를하면서롯데쇼핑에저장해둔이전집주소를수정하지않아서이전집으로배송이...ㅠ.ㅠ부랴부랴이전집으로가니다행이그집현관앞에떡하니있네요ㅎ이걸들고나가는데마치남의집물건훔쳐가는기분이..ㅡ.ㅡ여튼잘찾아와서개봉하고틀어보니첨엔하얀불이들어왔다가하늘색불로바뀌고금방파란색불빛으로바뀌더군요.아침에청소하고환기를시켜서인지공기질이매우양호하네요ㅎㅎ인생에첨써보는공기청정기라요긴하게써봐야겠네요\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "res = get_html(NAVER_SHOPPING_BASE_URL, KUKU_AC_25W20FPMO)[2]['body']\n",
    "print(\"Raw : \", res)\n",
    "print(\"1 : \", res.splitlines())\n",
    "print(\"2 : \", res.strip('\\n\\t\\s'))\n",
    "import re\n",
    "print(\"3 : \", re.sub(r\"[\\n\\t\\s]*\", \"\", res))\n",
    "print(\"4 : \", res.replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\" \", \"\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res = []\n",
    "for product_id in product_arr:\n",
    "    res.append(get_html(NAVER_SHOPPING_BASE_URL, product_id))\n",
    "    print(len(res))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2ce40b30d0e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheadless\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\CheonYoungJo\\\\Desktop\\\\Local_Repo\\\\Algorithm\\\\chromedriver.exe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplicitly_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdesired_capabilities\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[0mdesired_capabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_capabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0mdesired_capabilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_capabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: to_capabilities() missing 1 required positional argument: 'self'"
     ],
     "ename": "TypeError",
     "evalue": "to_capabilities() missing 1 required positional argument: 'self'",
     "output_type": "error"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options\n",
    "options.headless = True\n",
    "# Jupiter에서 driver 정상 동작 안함. \n",
    "# TypeError: to_capabilities() missing 1 required positional argument: 'self' 발생!\n",
    "driver = webdriver.Chrome(executable_path=\"C:\\\\Users\\\\CheonYoungJo\\\\Desktop\\\\Local_Repo\\\\Algorithm\\\\chromedriver.exe\", options=options)\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "#   if existReview:     리뷰가 존재하면 실행\n",
    "#       page = parsing  페이지 몇개인지 찾기\n",
    "#       while page:     모든 페이지 실행\n",
    "#          get_tag\n",
    "#          if existPage:   페이지가 더 있으면 스크립트 실행\n",
    "#             driver.execution_script()\n",
    "#             sleep()\n",
    "\n",
    "def get_html2(_url, _id):\n",
    "    r = requests.get(_url + _id)\n",
    "    html = BeautifulSoup(r.content, 'html.parser')\n",
    "    li_size = len(html.find_all(\"li\", attrs={'class': 'thumb_nail'}))\n",
    "    print(li_size)\n",
    "    \n",
    "get_html2(\"https://search.shopping.naver.com/detail/detail.nhn?nvMid=\", \"2131231231223213\")\n",
    "\n",
    "#container > div\n",
    "#_review_paging > a.next_end\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'python_test3'}\n",
      "{'name': 'els-1', 'cluster_name': 'elk-bigdata', 'cluster_uuid': 'J9cMv8YXRkeq0ThyNLAYYQ', 'version': {'number': '7.6.1', 'build_flavor': 'default', 'build_type': 'tar', 'build_hash': 'aa751e09be0a5072e8570670309b1f12348f023b', 'build_date': '2020-02-29T00:15:25.529771Z', 'build_snapshot': False, 'lucene_version': '8.4.0', 'minimum_wire_compatibility_version': '6.8.0', 'minimum_index_compatibility_version': '6.0.0-beta1'}, 'tagline': 'You Know, for Search'}\n",
      "(20, [])\n",
      "(20, [])\n",
      "(20, [])\n",
      "(20, [])\n",
      "(20, [])\n",
      "(20, [])\n",
      "(20, [])\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "{'_shards': {'total': 2, 'successful': 2, 'failed': 0}}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 78
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Elasticsearch 적재\n",
    "    Index Name Example : external-customer_review-제조사-모델명-200618\n",
    "\"\"\"\n",
    "\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import datetime, pprint, random, time\n",
    "import pandas as pd\n",
    "\n",
    "def make_index(_es, name):\n",
    "    if es.indices.exists(index=name):\n",
    "        es.indices.delete(index=name)\n",
    "    print(es.indices.create(index=name))\n",
    "\n",
    "\n",
    "es = Elasticsearch([\"13.125.246.197:9200\", \"52.79.215.253:9200\", \"52.79.250.228:9200\"])\n",
    "index_name = \"python_test3\"\n",
    "make_index(es, index_name)\n",
    "print(es.info())\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\"\"\"\n",
    "    중복 저장 X \n",
    "    DateFrame use to changing the datetime type to pandas.timestamp type.\n",
    "    Elasticsearch의 Bulk 함수를 이용하여 많은 데이터를 적재시키는 코드로 body array를 만들어 저장하는 방법.\n",
    "\"\"\"\n",
    "\n",
    "for office in res:\n",
    "    body = [\n",
    "        {\n",
    "            \"_index\": index_name,\n",
    "            \"_source\": x\n",
    "        }\n",
    "        for x in office\n",
    "    ]\n",
    "    res = helpers.bulk(es, body)\n",
    "    pp.pprint(res)\n",
    "    time.sleep(1)\n",
    "    \n",
    "es.indices.refresh(index=index_name)\n",
    "\n",
    "# Test Code\n",
    "# _id = ['test1', 'test2', 'test3', 'test4', 'test5', 'test6', 'test7']\n",
    "# _int = [1,2,3,4,5,6,7]\n",
    "# _bool = [True, False, True, False, True, False, True]\n",
    "# _date = [datetime.datetime.now(), datetime.datetime.now(), datetime.datetime.utcnow(), \n",
    "#          datetime.datetime.utcnow(), datetime.datetime.now(), datetime.datetime.utcnow(), datetime.datetime.now()]\n",
    "# \n",
    "# df = pd.DataFrame([x for x in zip(_id, _int, _bool, _date)], columns=['ID', 'INT', 'BOOL', 'Dat'])\n",
    "# print(df)\n",
    "# for i in zip(df['ID'], df['INT'], df['BOOL'], df['Dat']):\n",
    "#     print(i, type(i), i[3], type(i[3]))\n",
    "#     a = i[3].to_pydatetime()\n",
    "#     print(a, type(a))\n",
    "# \n",
    "# body = [\n",
    "#     {\n",
    "#         \"_index\": \"python_test2\",\n",
    "#         \"_source\": {\n",
    "#             \"Id\": x[0],\n",
    "#             \"In\": random.randint(0,10),\n",
    "#             \"Bol\": x[2],\n",
    "#             \"Dat\": datetime.datetime.utcnow()\n",
    "#         }\n",
    "#     }\n",
    "#     # for x in zip(_id, _int, _bool, _date)\n",
    "#     for x in zip(df['ID'], df['INT'], df['BOOL'], df['Dat'])\n",
    "# ]\n",
    "# \n",
    "# pp.pprint(body)\n",
    "# \n",
    "# # res = es.bulk(index=\"python_test\", body=body, doc_type='doc')\n",
    "# res = helpers.bulk(es, body)\n",
    "# pp.pprint(res)\n",
    "# \n",
    "# es.indices.refresh(index=\"python_test2\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}